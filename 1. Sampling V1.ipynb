{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sampling Version 1\n",
    "\n",
    "We'll start off by selecting videos for the study. As we've defined in the plan of approach, we will be studying two seperate samples. One from which we include the channels that are included, and one which dives into the general domain. This section will concern the former variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Document Prep:\n",
    "from pyforest import * # This library quickly imports most of the relevant Data Science libraries\n",
    "directory = '####'     # Set a working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Set-up the Service\n",
    "\n",
    "We'll be using the Youtube API to select videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate credentials:\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Api Keys\n",
    "api_key = \"####\"\n",
    "\n",
    "# Session Build\n",
    "youtube = build('youtube', 'v3', developerKey = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generate the Sample Using the Service\n",
    "\n",
    "Below we generate the sample by using the service, passing the channel ID's and populating dataframes. Since the present study focusses on science communication channels, you will find those 5 channels in the dictionary below; however, these may be interchanged at will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veritasium\n",
      "50 out of 600\n",
      "100 out of 600\n",
      "150 out of 600\n",
      "200 out of 600\n",
      "250 out of 600\n",
      "300 out of 600\n",
      "306 out of 600\n",
      "Results exhausted\n",
      "The Veritasium sample has been saved! \n",
      "\n",
      "VSauce\n",
      "50 out of 600\n",
      "100 out of 600\n",
      "150 out of 600\n",
      "200 out of 600\n",
      "250 out of 600\n",
      "300 out of 600\n",
      "350 out of 600\n",
      "366 out of 600\n",
      "Results exhausted\n",
      "The VSauce sample has been saved! \n",
      "\n",
      "Kurzgesagt\n",
      "50 out of 600\n",
      "100 out of 600\n",
      "141 out of 600\n",
      "Results exhausted\n",
      "The Kurzgesagt sample has been saved! \n",
      "\n",
      "Mark Rober\n",
      "50 out of 600\n",
      "98 out of 600\n",
      "Results exhausted\n",
      "The Mark Rober sample has been saved! \n",
      "\n",
      "asapSCIENCE\n",
      "50 out of 600\n",
      "100 out of 600\n",
      "150 out of 600\n",
      "200 out of 600\n",
      "250 out of 600\n",
      "300 out of 600\n",
      "350 out of 600\n",
      "359 out of 600\n",
      "Results exhausted\n",
      "The asapSCIENCE sample has been saved! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variant 1 Sample Generation\n",
    "channelids = {'Veritasium'  : 'UCHnyfMqiRRG1u-2MsSQLbXA',\n",
    "              'VSauce'      : 'UC6nSFpj9HTCZ5t-N3Rm3-HA',\n",
    "              'Kurzgesagt'  : 'UCsXVk37bltHxD1rDPwtNM8Q',\n",
    "              'Mark Rober'  : 'UCY1kMZp36IQSyNx_9h4mpCg',\n",
    "              'asapSCIENCE' : 'UCC552Sd-3nyi_tk2BudLUzA'}\n",
    "\n",
    "n     = 600\n",
    "iter  = range(1, (int(n/50+1)))\n",
    "order = 'rating'\n",
    "\n",
    "Raw_sample_V1 = pd.DataFrame(columns = [\"Video.ID\", \"Title\", \"Channel_Name\"])\n",
    "\n",
    "#Iterate through Channels\n",
    "for channelid in channelids.items():\n",
    "    \n",
    "    print(channelid[0])\n",
    "    \n",
    "    #Iterate iter number of times to fulfill n; there is a maximum of 50 results per search.\n",
    "    for i in iter:\n",
    "\n",
    "        if i == 1:\n",
    "            \n",
    "            # Search Request\n",
    "            request = youtube.search().list(\n",
    "                part       =\"snippet\",\n",
    "                type       = \"video\",\n",
    "                maxResults = n,\n",
    "                channelId  = channelid[1],    \n",
    "            ) \n",
    "\n",
    "            # Save response\n",
    "            response = request.execute()\n",
    "\n",
    "            # Unpack Respons\n",
    "            rows = []\n",
    "            \n",
    "            for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title'],\n",
    "                                item['snippet']['channelTitle']])\n",
    "\n",
    "            video_sample = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\", \"Channel_Name\"])\n",
    "            print(f'{len(video_sample)} out of {n}')\n",
    "        \n",
    "        else:\n",
    "            try:   \n",
    "                # Search Request\n",
    "                request = youtube.search().list(\n",
    "                    part       = \"snippet\",\n",
    "                    type       = \"video\",\n",
    "                    maxResults = n,\n",
    "                    channelId  = channelid[1],\n",
    "                    pageToken  = response['nextPageToken']    \n",
    "                ) \n",
    "\n",
    "                # Save response\n",
    "                response = request.execute()\n",
    "\n",
    "                # Unpack Respons\n",
    "                rows = []\n",
    "\n",
    "                for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title'],\n",
    "                                item['snippet']['channelTitle']])\n",
    "\n",
    "                video_sample_temp = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\", \"Channel_Name\"])\n",
    "                video_sample = video_sample.append(video_sample_temp)\n",
    "                print(f'{len(video_sample)} out of {n}')\n",
    "            \n",
    "            except(KeyError):\n",
    "                print(\"Results exhausted\")\n",
    "                break\n",
    "    \n",
    "    #Cleaning:\n",
    "    to_delete = ['#short', \n",
    "                 ' prank']\n",
    "    video_sample = video_sample[~video_sample['Title'].str.contains('|'.join(to_delete))] \n",
    "    \n",
    "    #Sampling:\n",
    "    if len(video_sample) > 200:\n",
    "        sample = video_sample.sample(n=200, \n",
    "                                     random_state=123,\n",
    "                                     replace = True)\n",
    "    else:\n",
    "        sample = video_sample\n",
    "    \n",
    "    Raw_sample_V1 = Raw_sample_V1.append(sample)\n",
    "    print(f'The {channelid[0]} sample has been saved! \\n')\n",
    "\n",
    "#Output:\n",
    "Raw_sample_V1.to_csv(f'{directory}Raw_Sample_V1.csv', \n",
    "                     sep=';', \n",
    "                     index=False, \n",
    "                     encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
