{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieval of Video Statistics\n",
    "\n",
    "Aside from just selecting videos we also want to collect as much information on said videos as possible. In order to do so, we will be using a different feature of the Youtube API; namely, the list feature. Here we are able to retrieve a myriad of video statistics for either of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Document Prep:\n",
    "from pyforest import * # This library quickly imports most of the relevant Data Science libraries\n",
    "directory = '####'     # Set a working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Set-up the Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate credentials:\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Api Keys\n",
    "key = \"#####\"\n",
    "\n",
    "# Session Build\n",
    "youtube = build('youtube', 'v3', developerKey = key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define the RetrieveStats() Function to Retrieve the Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveStats(df):\n",
    "    \n",
    "    #Initialize dictionary for the data points to collect:\n",
    "    stats = {\"publishedAt\"   : [], \n",
    "             \"duration\"      : [],\n",
    "             \"definition\"    : [],\n",
    "             \"viewCount\"     : [],\n",
    "             \"likeCount\"     : [],\n",
    "             \"dislikeCount\"  : [],\n",
    "             \"favoriteCount\" : [],\n",
    "             \"commentCount\"  : []}\n",
    "\n",
    "    # Execute request per Video ID\n",
    "    for vid in df['Video.ID']:\n",
    "        \n",
    "        # Formalize Request:\n",
    "        request = youtube.videos().list(\n",
    "                part =\"snippet,statistics,contentDetails\",\n",
    "                id   = vid\n",
    "            )\n",
    "        \n",
    "        # Save Response\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Store the data in the dictionary\n",
    "        try:\n",
    "            stats['publishedAt'].append(response['items'][0]['snippet']['publishedAt'])\n",
    "        except(KeyError):\n",
    "            stats['publishedAt'].append(np.nan)\n",
    "        try:\n",
    "            stats['duration'].append(response['items'][0]['contentDetails']['duration']) \n",
    "        except(KeyError):\n",
    "            stats['duration'].append(np.nan)\n",
    "        try:\n",
    "            stats['definition'].append(response['items'][0]['contentDetails']['definition']) \n",
    "        except(KeyError):\n",
    "            stats['definition'].append(np.nan)\n",
    "        try:\n",
    "            stats['viewCount'].append(response['items'][0]['statistics']['viewCount'])\n",
    "        except(KeyError):\n",
    "            stats['viewCount'].append(np.nan)\n",
    "        try:\n",
    "            stats['likeCount'].append(response['items'][0]['statistics']['likeCount']) \n",
    "        except(KeyError):\n",
    "            stats['likeCount'].append(np.nan)\n",
    "        try:\n",
    "            stats['dislikeCount'].append(response['items'][0]['statistics']['dislikeCount']) \n",
    "        except(KeyError):\n",
    "            stats['dislikeCount'].append(np.nan)\n",
    "        try:\n",
    "            stats['favoriteCount'].append(response['items'][0]['statistics']['favoriteCount'])\n",
    "        except(KeyError):\n",
    "            stats['favoriteCount'].append(np.nan)\n",
    "        try:\n",
    "            stats['commentCount'].append(response['items'][0]['statistics']['commentCount'])\n",
    "        except(KeyError):\n",
    "            stats['commentCount'].append(np.nan)\n",
    "            \n",
    "        # progress report:\n",
    "        current = raw_sample_V1[raw_sample_V1['Video.ID'] == vid].index[0] + 1\n",
    "        \n",
    "        if current % 50 == 0:\n",
    "            print(f'We are {(current/len(df)*100):.1f}% of the way there!')\n",
    "    \n",
    "    # Store data as a dataframe and concatenate it to the original:\n",
    "    stats = pd.DataFrame(stats)\n",
    "    df = pd.concat([df, stats], axis = 1)\n",
    "    \n",
    "    # Response summary:\n",
    "    print(f\"\\nWe couldn't find at least 1 statistic for {df.isna().sum().max()} videos. \\nSee a data loss overview below: \\n\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Retrieve and Save Video Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "raw_sample_V1 = pd.read_csv(f\"{directory}Sample_V1.csv\", ';')\n",
    "raw_sample_V1.reset_index(inplace = True) # done to improve the progress report.\n",
    "\n",
    "raw_sample_V1 = RetrieveStats(raw_sample_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to csv:\n",
    "raw_sample_V1.to_csv(f\"{directory}Sample_V1.csv\", sep = ';')\n",
    "#raw_sample_V2.to_csv(f\"{directory}Sample_V2.csv\", sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
