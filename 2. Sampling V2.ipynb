{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sampling Version 2 (OMITTED)\n",
    "\n",
    "As we've defined in the proposal, we will be studying two seperate samples. One from which we include videos from selected, and one which dives into the general domain. This section will regard the latter variant.\n",
    "\n",
    "**EDIT:**  \n",
    "This section was eventually scrapped and omitted from the actualy thesis because the videos retrieved did not concur with the sampling definition. We found it is rather difficult to accurate sample videos without passing channel ids. The code below shows how you could go about doing it; however, controlling your results will be an important challenge you will need to navigate.\n",
    "\n",
    "**EDIT 2:**  \n",
    "Also, please note this section was written at the very start of the thesis, using one singular function would make this code much more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Document Prep:\n",
    "from pyforest import * # This library quickly imports most of the relevant Data Science libraries\n",
    "directory = '####'     # Set a working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Set-up the Service\n",
    "\n",
    "We'll be using the Youtube API to select videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate credentials:\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Api Keys\n",
    "key = \"#####\"\n",
    "\n",
    "# Session Build\n",
    "youtube = build('youtube', 'v3', developerKey = key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate the Sample Using the Service\n",
    "\n",
    "Below we generate the sample by using the service. We will be searching based on Keywords as well as video ID's both will retrieve videos related to either parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant 2 Sample Generation\n",
    "keywords       = ['Global Warming',\n",
    "                  'Coronavirus',\n",
    "                  'Mars Rover',\n",
    "                  'Fusion Energy',\n",
    "                  'Genetic engineering']\n",
    "rand_selec_ids = ['IJ-h0SO8EUI',\n",
    "                  'LEZCxxKp0hM',\n",
    "                  'Y52e551lU50',\n",
    "                  '7u_cm5b1s7Y',\n",
    "                  'Lx4YuW3bagE',\n",
    "                  'dMdvwoldnko',\n",
    "                  'gIAsT2uDGxE',\n",
    "                  'H6u0VBqNBQ8',\n",
    "                  'F3QpgXBtDeo',\n",
    "                  'R13BD8qKeTg']\n",
    "order          = 'relevance'\n",
    "iter           = range(1, 150)\n",
    "\n",
    "Raw_sample_V2  = pd.DataFrame(columns = [\"Video.ID\", \"Title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Search Based on Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Iterate through Keywords\n",
    "for kw in keywords:\n",
    "    \n",
    "    print(f'Searching on {kw}')\n",
    "    \n",
    "    #Iterate iter number of times to fulfill n; there is a maximum of 50 results per search.\n",
    "    for i in range(1, 150):\n",
    "\n",
    "        if i == 1:\n",
    "            \n",
    "            # Search Request\n",
    "            request = youtube.search().list(\n",
    "                part              = \"snippet\",\n",
    "                q                 = kw,\n",
    "                type              = \"video\",\n",
    "                relevanceLanguage = 'en',\n",
    "                maxResults        = 2500,\n",
    "                videoCategoryId   = 28,\n",
    "                order             = order,\n",
    "                eventType         = \"completed\",\n",
    "                videoDefinition   = 'high',\n",
    "                videoDuration     = \"medium\"\n",
    "            )    \n",
    "                                                # Bug: It keeps copying ids and includes low quality videos.\n",
    "            # Save response\n",
    "            response = request.execute()\n",
    "\n",
    "            # Unpack Respons\n",
    "            rows = []\n",
    "            \n",
    "            for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title']])\n",
    "\n",
    "            video_sample = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\"])\n",
    "            print(f'{len(video_sample)} videos retrieved!')\n",
    "        \n",
    "        else:\n",
    "            try:   \n",
    "                # Search Request\n",
    "                request = youtube.search().list(\n",
    "                    part              = \"snippet\",\n",
    "                    q                 = kw,\n",
    "                    type              = \"video\",\n",
    "                    relevanceLanguage = 'en',\n",
    "                    maxResults        = 2500,\n",
    "                    videoCategoryId   = 28,\n",
    "                    order             = order,\n",
    "                    eventType         = \"completed\",\n",
    "                    videoDuration     = \"medium\",\n",
    "                    videoDefinition   = 'high',\n",
    "                    pageToken         = response['nextPageToken']\n",
    "                ) \n",
    "\n",
    "                # Save response\n",
    "                response = request.execute()\n",
    "\n",
    "                # Unpack Respons\n",
    "                rows = []\n",
    "\n",
    "                for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title']])\n",
    "\n",
    "                video_sample_temp = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\"])\n",
    "                video_sample = video_sample.append(video_sample_temp)\n",
    "                print(f'{len(video_sample)} videos retrieved!')\n",
    "            \n",
    "            except(KeyError):\n",
    "                print(\"\\n Results exhausted \\n\")\n",
    "                break\n",
    "    \n",
    "    #Cleaning:\n",
    "    to_delete = ['#short', \n",
    "                 ' prank',\n",
    "                 '[live]',\n",
    "                 '[LIVE]',\n",
    "                 'live ',\n",
    "                 'news',\n",
    "                 'summit']\n",
    "    #video_sample = video_sample[~video_sample['Title'].str.contains('|'.join(to_delete))] \n",
    "    # Exclusion omitted due to mixed results. \n",
    "    \n",
    "    #Output:\n",
    "    Raw_sample_V2 = Raw_sample_V2.append(video_sample)\n",
    "    print(f'The sample searched on {kw} has been saved! \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_sample_V2_kw.to_csv(f'{directory}Raw_Sample_kw.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Search Based on Related Video IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Iterate through Related Video IDs\n",
    "for rvi in rand_selec_ids:\n",
    "    \n",
    "    print(f'Searching {rand_selec_ids.index(rvi) +1} out of {len(rand_selec_ids)} videos')\n",
    "    \n",
    "    #Iterate iter number of times to fulfill n; there is a maximum of 50 results per search.\n",
    "    for i in range(1, 150):\n",
    "\n",
    "        if i == 1:\n",
    "            \n",
    "            # Search Request\n",
    "            request = youtube.search().list(\n",
    "                part              = \"snippet\",\n",
    "                q                 = kw,\n",
    "                type              = \"video\",\n",
    "                relevanceLanguage = 'en',\n",
    "                maxResults        = 2500,\n",
    "                videoCategoryId   = 28,\n",
    "                order             = order,\n",
    "                eventType         = \"completed\",\n",
    "                videoDefinition   = 'high',\n",
    "                videoDuration     = \"medium\"\n",
    "            )    \n",
    "                                                        # It keeps copying id's and includes low quality videos.\n",
    "            # Save response\n",
    "            response = request.execute()\n",
    "\n",
    "            # Unpack Respons\n",
    "            rows = []\n",
    "            \n",
    "            for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title']])\n",
    "\n",
    "            video_sample = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\"])\n",
    "            print(f'{len(video_sample)} videos retrieved!')\n",
    "        \n",
    "        else:\n",
    "            try:   \n",
    "                # Search Request\n",
    "                request = youtube.search().list(\n",
    "                    part              = \"snippet\",\n",
    "                    q                 = kw,\n",
    "                    type              = \"video\",\n",
    "                    relevanceLanguage = 'en',\n",
    "                    maxResults        = 2500,\n",
    "                    videoCategoryId   = 28,\n",
    "                    order             = order,\n",
    "                    eventType         = \"completed\",\n",
    "                    videoDuration     = \"medium\",\n",
    "                    videoDefinition   = 'high',\n",
    "                    pageToken         = response['nextPageToken']\n",
    "                ) \n",
    "\n",
    "                # Save response\n",
    "                response = request.execute()\n",
    "\n",
    "                # Unpack Respons\n",
    "                rows = []\n",
    "\n",
    "                for item in response['items']:\n",
    "\n",
    "                    rows.append([item['id']['videoId'],\n",
    "                                item['snippet']['title']])\n",
    "\n",
    "                video_sample_temp = pd.DataFrame(rows, columns = [\"Video.ID\", \"Title\"])\n",
    "                video_sample = video_sample.append(video_sample_temp)\n",
    "                print(f'{len(video_sample)} videos retrieved!')\n",
    "            \n",
    "            except(KeyError):\n",
    "                print(\"\\n Results exhausted \\n\")\n",
    "                break\n",
    "    \n",
    "    #Cleaning:\n",
    "    to_delete = ['#short', \n",
    "                 ' prank',\n",
    "                 '[live]',\n",
    "                 '[LIVE]',\n",
    "                 'live ',\n",
    "                 'news',\n",
    "                 'summit']\n",
    "    #video_sample = video_sample[~video_sample['Title'].str.contains('|'.join(to_delete))] \n",
    "    \n",
    "    #Output:\n",
    "    Raw_sample_V2_rvi = Raw_sample_V2.append(video_sample)\n",
    "    print(f'The sample searched on {kw} has been saved! \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_sample_V2_rvi.to_csv(f'{directory}Raw_Sample_rvi.csv', sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
